{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 01 - Bronze Load\n",
    "\n",
    "Ingest raw JSON sources from `data/raw` into DuckDB bronze tables.\n",
    "\n",
    "- Basic processing so that JSON or NDJSON can be loaded without data loss.\n",
    "- Falls back to a simple cleaner if the input file is loosely formatted.\n",
    "\n",
    "Gibbons, 2025-11-24\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import duckdb\n",
    "\n",
    "\"\"\"\n",
    "bronze_load.py\n",
    "---------\n",
    "Ingest from raw JSON sources\n",
    "\n",
    "- Basic processing to get into DuckDB without data loss\n",
    "\n",
    "Gibbons 2025_11_24\n",
    "\"\"\"\n",
    "\n",
    "# ---------------------------\n",
    "# Project paths\n",
    "# ---------------------------\n",
    "\n",
    "if \"__file__\" in globals():\n",
    "    # Running as a .py script\n",
    "    THIS_FILE = Path(__file__).resolve()\n",
    "    SRC_DIR = THIS_FILE.parents[1]          # .../src\n",
    "    PROJECT_ROOT = THIS_FILE.parents[2]     # .../sales_test\n",
    "else:\n",
    "    # Running inside a notebook or REPL.\n",
    "    # Walk up from the current working directory until we find a folder\n",
    "    # that contains src/pipelines. Treat that as the project root.\n",
    "    cwd = Path.cwd()\n",
    "    PROJECT_ROOT = cwd\n",
    "    for candidate in [cwd] + list(cwd.parents):\n",
    "        if (candidate / \"src\" / \"pipelines\").exists():\n",
    "            PROJECT_ROOT = candidate\n",
    "            break\n",
    "\n",
    "    SRC_DIR = PROJECT_ROOT / \"src\"\n",
    "\n",
    "DB_PATH = SRC_DIR / \"sales.duckdb\"\n",
    "RAW_DIR = PROJECT_ROOT / \"data\" / \"raw\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON validator (optional, for debugging)\n",
    "\n",
    "Quick sanity check that each non-empty line parses as JSON. Handy if a file fails to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_json_lines(path: Path) -> None:\n",
    "    \"\"\"Quick sanity check: try to parse each non-empty line as JSON.\"\"\"\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for i, line in enumerate(f, start=1):\n",
    "            text = line.strip()\n",
    "            if not text:\n",
    "                continue\n",
    "\n",
    "            # Many line-delimited JSON files use one object per line.\n",
    "            # If there are trailing commas, strip them before validating.\n",
    "            if text.endswith(\",\"):\n",
    "                text = text[:-1]\n",
    "\n",
    "            try:\n",
    "                json.loads(text)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"[VALIDATION] Possible malformed JSON in {path} at line {i}: {e}\")\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaner: loose JSON to NDJSON\n",
    "\n",
    "Simple fixer that trims blank lines and trailing commas, then writes one JSON object per line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_to_ndjson(path: Path) -> Path:\n",
    "    \"\"\"Convert loosely formatted JSON list into NDJSON (one JSON object per line).\n",
    "    Removes trailing commas and blank lines, writes a temporary fixed file.\n",
    "    \"\"\"\n",
    "    fixed_path = path.with_name(path.stem + \"_fixed.json\")\n",
    "\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as src, fixed_path.open(\"w\", encoding=\"utf-8\") as dst:\n",
    "        for line in src:\n",
    "            cleaned = line.strip()\n",
    "\n",
    "            if not cleaned:\n",
    "                continue  # skip blank lines\n",
    "\n",
    "            if cleaned.endswith(\",\"):\n",
    "                cleaned = cleaned[:-1]  # remove trailing comma\n",
    "\n",
    "            dst.write(cleaned + \"\\n\")\n",
    "\n",
    "    return fixed_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bronze loader\n",
    "\n",
    "Load each JSON file from `data/raw` into its own DuckDB table in the bronze layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bronze_table(\n",
    "    con: duckdb.DuckDBPyConnection,\n",
    "    filename: str,\n",
    "    table_name: str,\n",
    ") -> None:\n",
    "    \"\"\"Load a single JSON file from data/raw into a DuckDB table in the bronze layer.\n",
    "\n",
    "    Strategy:\n",
    "     1. Try to load as normal JSON with read_json_auto().\n",
    "     2. If that fails, being malformed, clean it into NDJSON and retry with read_ndjson_auto().\n",
    "    \"\"\"\n",
    "    file_path = RAW_DIR / filename\n",
    "\n",
    "    if not file_path.exists():\n",
    "        raise FileNotFoundError(f\"Expected file not found: {file_path}\")\n",
    "\n",
    "    print(f\"Loading {file_path} -> {table_name}\")\n",
    "\n",
    "    # First attempt: assume the file is valid JSON.\n",
    "    try:\n",
    "        con.execute(\n",
    "            f\"\"\"\n",
    "            CREATE OR REPLACE TABLE {table_name} AS\n",
    "            SELECT *\n",
    "            FROM read_json_auto(?)\n",
    "            \"\"\",\n",
    "            [str(file_path)],\n",
    "        )\n",
    "        return  # success, we are done\n",
    "\n",
    "    except duckdb.InvalidInputException as e:\n",
    "        print(f\"[WARN] Initial JSON load failed for {file_path}\")\n",
    "        print(f\"[WARN] DuckDB said: {e}\")\n",
    "        print(\"[INFO] Attempting to clean file into NDJSON and reload...\")\n",
    "\n",
    "        # validate_json_lines(file_path)\n",
    "\n",
    "        fixed_path = fix_to_ndjson(file_path)\n",
    "\n",
    "        try:\n",
    "            con.execute(\n",
    "                f\"\"\"\n",
    "                CREATE OR REPLACE TABLE {table_name} AS\n",
    "                SELECT *\n",
    "                FROM read_ndjson_auto(?)\n",
    "                \"\"\",\n",
    "                [str(fixed_path)],\n",
    "            )\n",
    "            print(f\"[INFO] Loaded cleaned NDJSON file {fixed_path} -> {table_name}\")\n",
    "        except duckdb.InvalidInputException as e2:\n",
    "            print(f\"[ERROR] Even cleaned NDJSON version failed for {file_path}\")\n",
    "            print(f\"[ERROR] DuckDB reported: {e2}\")\n",
    "            # make pipeline fail loudly if this happens\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entry point\n",
    "\n",
    "Connect to DuckDB, load all bronze tables, then close the connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to DuckDB at c:\\Projects\\sales_test\\src\\sales.duckdb\n",
      "Raw data folder: c:\\Projects\\sales_test\\data\\raw\n",
      "Loading c:\\Projects\\sales_test\\data\\raw\\customers.json -> bronze_customers\n",
      "[WARN] Initial JSON load failed for c:\\Projects\\sales_test\\data\\raw\\customers.json\n",
      "[WARN] DuckDB said: Invalid Input Error: Malformed JSON in file \"c:\\Projects\\sales_test\\data\\raw\\customers.json\", at byte 1 in record/value 3: unexpected character. \n",
      "\n",
      "LINE 4:             FROM read_json_auto(?)\n",
      "                         ^\n",
      "[INFO] Attempting to clean file into NDJSON and reload...\n",
      "[INFO] Loaded cleaned NDJSON file c:\\Projects\\sales_test\\data\\raw\\customers_fixed.json -> bronze_customers\n",
      "Loading c:\\Projects\\sales_test\\data\\raw\\products.json -> bronze_products\n",
      "[WARN] Initial JSON load failed for c:\\Projects\\sales_test\\data\\raw\\products.json\n",
      "[WARN] DuckDB said: Invalid Input Error: Malformed JSON in file \"c:\\Projects\\sales_test\\data\\raw\\products.json\", at byte 1 in record/value 3: unexpected character. \n",
      "\n",
      "LINE 4:             FROM read_json_auto(?)\n",
      "                         ^\n",
      "[INFO] Attempting to clean file into NDJSON and reload...\n",
      "[INFO] Loaded cleaned NDJSON file c:\\Projects\\sales_test\\data\\raw\\products_fixed.json -> bronze_products\n",
      "Loading c:\\Projects\\sales_test\\data\\raw\\orders.json -> bronze_orders\n",
      "[WARN] Initial JSON load failed for c:\\Projects\\sales_test\\data\\raw\\orders.json\n",
      "[WARN] DuckDB said: Invalid Input Error: Malformed JSON in file \"c:\\Projects\\sales_test\\data\\raw\\orders.json\", at byte 1 in record/value 3: unexpected character. \n",
      "\n",
      "LINE 4:             FROM read_json_auto(?)\n",
      "                         ^\n",
      "[INFO] Attempting to clean file into NDJSON and reload...\n",
      "[INFO] Loaded cleaned NDJSON file c:\\Projects\\sales_test\\data\\raw\\orders_fixed.json -> bronze_orders\n",
      "Loading c:\\Projects\\sales_test\\data\\raw\\sales.json -> bronze_sales\n",
      "[WARN] Initial JSON load failed for c:\\Projects\\sales_test\\data\\raw\\sales.json\n",
      "[WARN] DuckDB said: Invalid Input Error: Malformed JSON in file \"c:\\Projects\\sales_test\\data\\raw\\sales.json\", at byte 1 in record/value 3: unexpected character. \n",
      "\n",
      "LINE 4:             FROM read_json_auto(?)\n",
      "                         ^\n",
      "[INFO] Attempting to clean file into NDJSON and reload...\n",
      "[INFO] Loaded cleaned NDJSON file c:\\Projects\\sales_test\\data\\raw\\sales_fixed.json -> bronze_sales\n",
      "Loading c:\\Projects\\sales_test\\data\\raw\\countries.json -> bronze_countries\n",
      "[WARN] Initial JSON load failed for c:\\Projects\\sales_test\\data\\raw\\countries.json\n",
      "[WARN] DuckDB said: Invalid Input Error: Malformed JSON in file \"c:\\Projects\\sales_test\\data\\raw\\countries.json\", at byte 1 in record/value 3: unexpected character. \n",
      "\n",
      "LINE 4:             FROM read_json_auto(?)\n",
      "                         ^\n",
      "[INFO] Attempting to clean file into NDJSON and reload...\n",
      "[INFO] Loaded cleaned NDJSON file c:\\Projects\\sales_test\\data\\raw\\countries_fixed.json -> bronze_countries\n",
      "Bronze layer finished.\n"
     ]
    }
   ],
   "source": [
    "def main() -> None:\n",
    "    print(f\"Connecting to DuckDB at {DB_PATH}\")\n",
    "    print(f\"Raw data folder: {RAW_DIR}\")\n",
    "\n",
    "    con = duckdb.connect(str(DB_PATH))\n",
    "\n",
    "    tables_to_load = [\n",
    "        (\"customers.json\", \"bronze_customers\"),\n",
    "        (\"products.json\", \"bronze_products\"),\n",
    "        (\"orders.json\", \"bronze_orders\"),\n",
    "        (\"sales.json\", \"bronze_sales\"),\n",
    "        (\"countries.json\", \"bronze_countries\"),\n",
    "    ]\n",
    "\n",
    "    for filename, table_name in tables_to_load:\n",
    "        load_bronze_table(con, filename, table_name)\n",
    "\n",
    "    con.close()\n",
    "    print(\"Bronze layer finished.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sales-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
