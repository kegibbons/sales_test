{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 04 - Export Medallion Layers\n",
        "\n",
        "Export bronze, silver, and gold tables from DuckDB to disk.\n",
        "\n",
        "- Bronze → JSON + metadata under `data/bronze`\n",
        "- Silver → JSON + metadata under `data/silver`\n",
        "- Gold   → Parquet + metadata under `data/gold`\n",
        "\n",
        "Paths are resolved from this file/notebook location, not the current working directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import duckdb\n",
        "\n",
        "\"\"\"\n",
        "step04_export_medallion_layers.py\n",
        "\n",
        "Exports the medallion tables from DuckDB to disk:\n",
        "\n",
        "- Bronze  -> JSON + metadata under data/bronze\n",
        "- Silver  -> JSON + metadata under data/silver\n",
        "- Gold    -> Parquet + metadata under data/gold\n",
        "\n",
        "This script is location-agnostic: paths are resolved from this file's\n",
        "location (…/src/pipelines), not from the current working directory.\n",
        "\"\"\"\n",
        "\n",
        "# ----------------------------\n",
        "# Paths\n",
        "# ----------------------------\n",
        "\n",
        "# This file: …/src/pipelines/step04_export_medallion_layers.py\n",
        "if \"__file__\" in globals():\n",
        "    THIS_FILE = Path(__file__).resolve()\n",
        "else:\n",
        "    THIS_FILE = Path().resolve()\n",
        "\n",
        "SRC_DIR = THIS_FILE.parents[1]              # …/src\n",
        "PROJECT_ROOT = THIS_FILE.parents[2]         # …/sales_test\n",
        "\n",
        "DB_PATH = SRC_DIR / \"sales.duckdb\"          # …/src/sales.duckdb\n",
        "\n",
        "DATA_DIR = PROJECT_ROOT / \"data\"            # …/data\n",
        "BRONZE_DIR = DATA_DIR / \"bronze\"\n",
        "SILVER_DIR = DATA_DIR / \"silver\"\n",
        "GOLD_DIR = DATA_DIR / \"gold\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Table collections\n",
        "\n",
        "Lists of tables to export per layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "BRONZE_TABLES = [\n",
        "    \"bronze_customers\",\n",
        "    \"bronze_orders\",\n",
        "    \"bronze_sales\",\n",
        "    \"bronze_products\",\n",
        "    \"bronze_countries\",\n",
        "]\n",
        "\n",
        "SILVER_TABLES = [\n",
        "    \"silver_customers\",\n",
        "    \"silver_orders\",\n",
        "    \"silver_sales\",\n",
        "    \"silver_products\",\n",
        "    \"silver_countries\",\n",
        "    \"silver_fact_sales\",\n",
        "]\n",
        "\n",
        "GOLD_TABLES = [\n",
        "    \"gold_dim_customer\",\n",
        "    \"gold_dim_product\",\n",
        "    \"gold_dim_country\",\n",
        "    \"gold_dim_date\",\n",
        "    \"gold_fact_sales\",\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Directory setup\n",
        "\n",
        "Ensure the export folders exist."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ensure_dirs() -> None:\n",
        "    for d in (DATA_DIR, BRONZE_DIR, SILVER_DIR, GOLD_DIR):\n",
        "        d.mkdir(parents=True, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export functions\n",
        "\n",
        "Helpers to dump tables as JSON or Parquet and write metadata sidecars."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def export_table_json(\n",
        "    con: duckdb.DuckDBPyConnection,\n",
        "    table_name: str,\n",
        "    out_dir: Path,\n",
        ") -> Path:\n",
        "    out_path = out_dir / f\"{table_name}.json\"\n",
        "    sql = f\"COPY (SELECT * FROM {table_name}) TO ? (FORMAT JSON);\"\n",
        "    con.execute(sql, [str(out_path)])\n",
        "    return out_path\n",
        "\n",
        "\n",
        "def export_table_parquet(\n",
        "    con: duckdb.DuckDBPyConnection,\n",
        "    table_name: str,\n",
        "    out_dir: Path,\n",
        ") -> Path:\n",
        "    out_path = out_dir / f\"{table_name}.parquet\"\n",
        "    sql = f\"COPY (SELECT * FROM {table_name}) TO ? (FORMAT PARQUET);\"\n",
        "    con.execute(sql, [str(out_path)])\n",
        "    return out_path\n",
        "\n",
        "\n",
        "def write_table_metadata(\n",
        "    con: duckdb.DuckDBPyConnection,\n",
        "    table_name: str,\n",
        "    out_dir: Path,\n",
        ") -> Path:\n",
        "    (row_count,) = con.execute(\n",
        "        f\"SELECT COUNT(*) FROM {table_name}\"\n",
        "    ).fetchone()\n",
        "\n",
        "    schema_rows = con.execute(\n",
        "        f\"PRAGMA table_info({table_name})\"\n",
        "    ).fetchall()\n",
        "\n",
        "    columns = [\n",
        "        {\n",
        "            \"name\": r[1],\n",
        "            \"type\": r[2],\n",
        "            \"not_null\": bool(r[3]),\n",
        "            \"primary_key\": bool(r[5]),\n",
        "        }\n",
        "        for r in schema_rows\n",
        "    ]\n",
        "\n",
        "    meta = {\n",
        "        \"table\": table_name,\n",
        "        \"row_count\": row_count,\n",
        "        \"columns\": columns,\n",
        "    }\n",
        "\n",
        "    out_path = out_dir / f\"{table_name}.meta.json\"\n",
        "    with out_path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(meta, f, indent=2)\n",
        "\n",
        "    return out_path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export helpers per layer\n",
        "\n",
        "Bronze/silver export as JSON; gold as Parquet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dump_table_set(\n",
        "    con: duckdb.DuckDBPyConnection,\n",
        "    tables: list[str],\n",
        "    out_dir: Path,\n",
        "    label: str,\n",
        ") -> None:\n",
        "    print(f\"\\n=== Exporting {label} tables to {out_dir} ===\")\n",
        "    for t in tables:\n",
        "        print(f\"  -> {t} ...\", end=\"\", flush=True)\n",
        "        try:\n",
        "            data_path = export_table_json(con, t, out_dir)\n",
        "            meta_path = write_table_metadata(con, t, out_dir)\n",
        "            print(f\" done [{data_path.name}, {meta_path.name}]\")\n",
        "        except Exception as e:\n",
        "            print(f\" FAILED ({e})\")\n",
        "\n",
        "\n",
        "def dump_gold_tables(\n",
        "    con: duckdb.DuckDBPyConnection,\n",
        "    tables: list[str],\n",
        "    out_dir: Path,\n",
        ") -> None:\n",
        "    print(f\"\\n=== Exporting gold tables to {out_dir} ===\")\n",
        "    for t in tables:\n",
        "        print(f\"  -> {t} ...\", end=\"\", flush=True)\n",
        "        try:\n",
        "            data_path = export_table_parquet(con, t, out_dir)\n",
        "            meta_path = write_table_metadata(con, t, out_dir)\n",
        "            print(f\" done [{data_path.name}, {meta_path.name}]\")\n",
        "        except Exception as e:\n",
        "            print(f\" FAILED ({e})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Main entry\n",
        "\n",
        "Connect to DuckDB, export all layers, and close the connection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def main() -> None:\n",
        "    ensure_dirs()\n",
        "\n",
        "    if not DB_PATH.exists():\n",
        "        raise FileNotFoundError(f\"DuckDB file not found at {DB_PATH}\")\n",
        "\n",
        "    print(f\"Connecting to DuckDB at {DB_PATH}...\")\n",
        "    con = duckdb.connect(str(DB_PATH))\n",
        "\n",
        "    try:\n",
        "        # bronze snapshot (json)\n",
        "        dump_table_set(con, BRONZE_TABLES, BRONZE_DIR, label=\"bronze\")\n",
        "\n",
        "        # silver snapshot (json)\n",
        "        dump_table_set(con, SILVER_TABLES, SILVER_DIR, label=\"silver\")\n",
        "\n",
        "        # gold snapshot (parquet)\n",
        "        dump_gold_tables(con, GOLD_TABLES, GOLD_DIR)\n",
        "\n",
        "        print(\"\\nAll exports complete.\")\n",
        "    finally:\n",
        "        con.close()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
